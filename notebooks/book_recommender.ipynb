{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f05e95-60d4-46e8-96d0-8396c2c144bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendation_trainer.py\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# user ratings must be at least this good to be used for training\n",
    "rating_threshold = 5\n",
    "# the number of books used for the query tower (# of isbns in input)\n",
    "n_isbns_in = 3\n",
    "\n",
    "base_dir = '/data/book_recommender'\n",
    "weights_dir = base_dir +'/{}-weights'\n",
    "index_model_dir = base_dir + '/model'\n",
    "tfjs_model_dir = base_dir + '/tfjs-model'\n",
    "\n",
    "# create a list of all isbn values\n",
    "isbns = []\n",
    "with open(base_dir + '/books.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        isbns.append(line[0])\n",
    "\n",
    "# create a lookup dictionary to convert isbn values to their index in the above list\n",
    "isbn_idxs = {isbn:idx for idx, isbn in enumerate(isbns)}\n",
    "with open(base_dir + '/isbn_idxs.csv', 'w') as file:\n",
    "    file.write('isbn,index\\n')\n",
    "    for isbn,index in isbn_idxs.items():\n",
    "        file.write('{},{}\\n'.format(isbn,index))\n",
    "n_isbns = len(isbn_idxs)\n",
    "\n",
    "# create a dictionary of all isbns that a user rates >= the rating_threshold\n",
    "user_isbns = {}\n",
    "with open(base_dir + '/ratings.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        rating = int(line[2])\n",
    "        if rating < rating_threshold:\n",
    "            continue\n",
    "        user_id = line[0]\n",
    "        isbn = line[1]\n",
    "        try:\n",
    "            isbn_idx = isbn_idxs[isbn]\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            user_isbns[user_id].append(isbn_idx)\n",
    "        except:\n",
    "            user_isbns[user_id] = [isbn_idx]\n",
    "\n",
    "user_isbns = dict(filter(lambda x: len(x[1]) >= n_isbns_in, user_isbns.items()))\n",
    "user_idxs = {user_id:idx for idx, user_id in enumerate(user_isbns.keys())}\n",
    "with open(base_dir + '/user_idxs.csv', 'w') as file:\n",
    "    file.write('user_id,index\\n')\n",
    "    for user_id, index in user_idxs.items():\n",
    "        file.write('{},{}\\n'.format(user_id,index))\n",
    "n_users = len(user_idxs)\n",
    "\n",
    "# create a dictionary of inputs and outputs\n",
    "dataset = {'isbns': [], 'user': []}\n",
    "for user_id, isbns in user_isbns.items():\n",
    "    # use 5x the number of isbns gathered for the user\n",
    "    # this ensures a larger amount of training data\n",
    "    for _ in range(len(isbns) * 5):\n",
    "        # randomly select n_isbns_in from the user's isbns\n",
    "        selected_isbns = np.random.choice(isbns, n_isbns_in)\n",
    "        # add them to the inputs\n",
    "        dataset['isbns'].append(selected_isbns)\n",
    "        # add the user to the output\n",
    "        dataset['user'].append(user_idxs[user_id])\n",
    "        \n",
    "# create a permutation to randomly shuffle all of the above data\n",
    "# a permutation is created first so the same order can be applied\n",
    "# to the inputs and the outputs\n",
    "permutation = np.random.permutation(len(dataset['isbns']))\n",
    "# apply the above permutation to the inputs and the outputs\n",
    "dataset = {\n",
    "    'isbns': np.asarray(dataset['isbns'])[permutation],\n",
    "    'user': np.asarray(dataset['user'])[permutation]\n",
    "}\n",
    "# convert the above dictionary to a TF Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "\n",
    "# print an example of the data in the dataset\n",
    "for d in dataset.take(1):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133d523-9c50-4e51-a3b3-0f2ef67ab177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the query and candidate models\n",
    "n_embedding_dimensions = 24\n",
    "\n",
    "## QUERY\n",
    "isbns_in_in = tf.keras.Input(shape=(n_isbns_in))\n",
    "isbns_in_emb = tf.keras.layers.Embedding(n_isbns+1, n_embedding_dimensions)(isbns_in_in)\n",
    "isbns_in_emb_avg = tf.keras.layers.AveragePooling1D(pool_size=3)(isbns_in_emb)\n",
    "query = tf.keras.layers.Flatten()(isbns_in_emb_avg)\n",
    "query_model = tf.keras.Model(inputs=isbns_in_in, outputs=query)\n",
    "\n",
    "## CANDIDATE\n",
    "isbns_out_in = tf.keras.Input(shape=(1))\n",
    "isbns_out_emb = tf.keras.layers.Embedding(n_users+1, n_embedding_dimensions)(isbns_out_in)\n",
    "candidate = tf.keras.layers.Flatten()(isbns_out_emb)\n",
    "candidate_model = tf.keras.Model(inputs=isbns_out_in, outputs=candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58527d-28cf-41d2-9431-d81c2da989cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFRS TASK SETUP\n",
    "candidates = dataset.batch(128).map(lambda x: candidate_model(x['user']))\n",
    "metrics = tfrs.metrics.FactorizedTopK(candidates=candidates)\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)\n",
    "\n",
    "\n",
    "## TFRS MODEL CLASS\n",
    "class Model(tfrs.Model):\n",
    "    def __init__(self, query_model, candidate_model):\n",
    "        super().__init__()\n",
    "        self._query_model = query_model\n",
    "        self._candidate_model = candidate_model\n",
    "        self._task = task\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        query_embedding = self._query_model(features['isbns'])\n",
    "        candidate_embedding = self._candidate_model(features['user'])\n",
    "        return self._task(query_embedding, candidate_embedding)\n",
    "\n",
    "## COMPILE AND TRAIN MODEL\n",
    "model = Model(query_model, candidate_model)\n",
    "# load model weights - this is to resume training\n",
    "# model._query_model.load_weights(weights_dir.format('query'))\n",
    "# model._candidate_model.load_weights(weights_dir.format('candidate'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "model.fit(dataset.repeat().shuffle(300_000).batch(4096), steps_per_epoch=50, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d2b77-d1aa-4da0-a1ca-50c791c9d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "model._query_model.save_weights(weights_dir.format('query'))\n",
    "model._candidate_model.save_weights(weights_dir.format('candidate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b5204-b0d9-4299-8c76-4fcadbe9053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the index model to lookup the best candidate match for a query\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model._query_model)\n",
    "index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((\n",
    "      dataset.map(lambda x: x['user']).batch(100),\n",
    "      dataset.batch(100).map(lambda x: model._candidate_model(x['user']))\n",
    "    ))\n",
    ")\n",
    "for features in dataset.shuffle(2000).batch(1).take(1):\n",
    "    print('isbns', features['isbns'])\n",
    "    scores, users = index(features['isbns'])\n",
    "    print('recommended users', users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f118c0-e53d-4ef3-8035-0cf55dcaf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index model\n",
    "index.save(index_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cddbd-914c-472e-9da9-57a87a52c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONVERT TO TFJS MODEL\n",
    "import subprocess\n",
    "cmd = [\n",
    "    'tensorflowjs_converter',\n",
    "    '--input_format=tf_saved_model',\n",
    "    '--output_format=tfjs_graph_model',\n",
    "    index_model_dir,\n",
    "    tfjs_model_dir\n",
    "]\n",
    "subprocess.run(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
